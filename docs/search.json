[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kuan-Ling Tseng (Rebecca)",
    "section": "",
    "text": "Welcome!!!"
  },
  {
    "objectID": "hw1_questions.html",
    "href": "hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn the experiment, the authors collaborated with a nonprofit organization and conducted a large-scale field experiment involving over 50,000 prior donors. Each donor was randomly assigned to receive one of several types of direct-mail fundraising letters.\nThe control group received a standard letter with no match offer, while the treatment groups received a matching grant offer, where an anonymous donor pledged to match donations at a rate of 1:1, 2:1, or 3:1. Additionally, the letters varied in their presentation of the suggested donation amount and the total match cap ($25,000 / $50,000 / $100,000 / unstated).\nThe researchers then tracked each recipient’s response—specifically: • Whether they donated at all (gave) • How much they donated (amount)\nThis allowed the authors to examine whether matching grants increase donations, whether the size of the match ratio matters, and how the differences influence donor behavior.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "hw1_questions.html#introduction",
    "href": "hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn the experiment, the authors collaborated with a nonprofit organization and conducted a large-scale field experiment involving over 50,000 prior donors. Each donor was randomly assigned to receive one of several types of direct-mail fundraising letters.\nThe control group received a standard letter with no match offer, while the treatment groups received a matching grant offer, where an anonymous donor pledged to match donations at a rate of 1:1, 2:1, or 3:1. Additionally, the letters varied in their presentation of the suggested donation amount and the total match cap ($25,000 / $50,000 / $100,000 / unstated).\nThe researchers then tracked each recipient’s response—specifically: • Whether they donated at all (gave) • How much they donated (amount)\nThis allowed the authors to examine whether matching grants increase donations, whether the size of the match ratio matters, and how the differences influence donor behavior.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "hw1_questions.html#data",
    "href": "hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\nimport pandas as pd\n\ndf = pd.read_stata(\"./data/karlan_list_2007.dta\", iterator=False)\ndf.head()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\n\n\n\ndf.describe()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio2\nratio3\nsize25\nsize50\nsize100\nsizeno\naskd1\naskd2\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\ncount\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n...\n49978.000000\n49978.000000\n48217.000000\n48047.000000\n48217.000000\n48221.000000\n48209.000000\n48214.000000\n48215.000000\n48217.000000\n\n\nmean\n0.666813\n0.333187\n0.222311\n0.222211\n0.166723\n0.166623\n0.166723\n0.166743\n0.222311\n0.222291\n...\n0.510245\n0.488715\n0.819599\n0.086710\n0.321694\n2.429012\n54815.700533\n0.669418\n0.391661\n0.871968\n\n\nstd\n0.471357\n0.471357\n0.415803\n0.415736\n0.372732\n0.372643\n0.372732\n0.372750\n0.415803\n0.415790\n...\n0.499900\n0.499878\n0.168561\n0.135868\n0.103039\n0.378115\n22027.316665\n0.193405\n0.186599\n0.258654\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.009418\n0.000000\n0.000000\n0.000000\n5000.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.755845\n0.014729\n0.258311\n2.210000\n39181.000000\n0.560222\n0.235647\n0.884929\n\n\n50%\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n0.000000\n0.872797\n0.036554\n0.305534\n2.440000\n50673.000000\n0.712296\n0.373744\n1.000000\n\n\n75%\n1.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n1.000000\n0.938827\n0.090882\n0.369132\n2.660000\n66005.000000\n0.816798\n0.530036\n1.000000\n\n\nmax\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n0.989622\n0.997544\n5.270000\n200001.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n8 rows × 48 columns\n\n\n\ntodo: Read the data into R/Python and describe the data\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nfrom sklearn import linear_model\nimport numpy as np\n\ntest_variables = [\"hpa\", \"mrm2\", \"freq\", \"years\", \"year5\", \"dormant\"]\n\n\ndef compare_ttest_regress(variable):\n\n    subset = df[[\"treatment\", variable]].dropna()\n    treat = subset[subset[\"treatment\"] == 1][variable]\n    control = subset[subset[\"treatment\"] == 0][variable]\n\n    # t-test\n    mean_diff = treat.mean() - control.mean()\n    var_treat = treat.var(ddof=1)\n    var_control = control.var(ddof=1)\n    se = np.sqrt(var_treat / len(treat) + var_control / len(control))\n    t_stat = mean_diff / se\n    ttest_result = round(t_stat, 2)\n\n    # regression\n    X = subset[\"treatment\"].values.reshape(-1, 1)\n    y = subset[variable].values\n    reg = linear_model.LinearRegression()\n    reg.fit(X, y)\n    reg_result = round(reg.coef_[0] / se, 2)\n\n    return ttest_result, reg_result\n\n\nresults = []\nfor v in test_variables:\n    results.append(\n        {\n            \"variable\": v,\n            \"t_test\": compare_ttest_regress(v)[0],\n            \"regress\": compare_ttest_regress(v)[1],\n        }\n    )\n\ndf_result = pd.DataFrame(results)\ndf_result\n\n\n\n\n\n\n\n\nvariable\nt_test\nregress\n\n\n\n\n0\nhpa\n0.97\n0.97\n\n\n1\nmrm2\n0.12\n0.12\n\n\n2\nfreq\n-0.11\n-0.11\n\n\n3\nyears\n-1.09\n-1.09\n\n\n4\nyear5\n-1.56\n-1.56\n\n\n5\ndormant\n0.17\n0.17"
  },
  {
    "objectID": "hw1_questions.html#experimental-results",
    "href": "hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nimport matplotlib.pyplot as plt\n\n\ndf_treat = df.query(\"treatment==1\")\ndf_control = df.query(\"control==1\")\ntreat_prop = df_treat[\"gave\"].value_counts(normalize=True)\ncontrol_prop = df_control[\"gave\"].value_counts(normalize=True)\n\nfig, ax = plt.subplots()\nbars = ax.bar(\n    [\"treat\", \"control\"],\n    [treat_prop[1] * 100, control_prop[1] * 100],\n    color=[\"skyblue\", \"orange\"],\n)\n\nfor bar in bars:\n    height = bar.get_height()\n    ax.annotate(\n        f\"{height:.1f}%\",\n        xy=(bar.get_x() + bar.get_width() / 2, height),\n        xytext=(0, 2),\n        textcoords=\"offset points\",\n        ha=\"center\",\n        va=\"bottom\",\n    )\n\n\n\n\n\n\n\n\n\ntreat = df[df[\"treatment\"] == 1][\"gave\"]\ncontrol = df[df[\"treatment\"] == 0][\"gave\"]\n# t-test\nmean_diff = treat.mean() - control.mean()\nvar_treat = treat.var(ddof=1)\nvar_control = control.var(ddof=1)\nse = np.sqrt(var_treat / len(treat) + var_control / len(control))\nt_stat = mean_diff / se\nttest_result = round(t_stat, 2)\nttest_result\n\nnp.float64(3.21)\n\n\nSince the t-test result is so large, we can conclude that the treatment group is significantly more willing to donate than the control group.\n\n# regression\nX = df[\"treatment\"].values.reshape(-1, 1)\ny = df[\"gave\"].values\nreg = linear_model.LinearRegression()\nreg.fit(X, y)\nreg_result = round(reg.coef_[0] / se, 2)\nreg_result\n\nnp.float64(3.21)\n\n\nAccording to the linear regression model, the coefficient is so big that we can conclude that the treatment group is more likely to donate than the control group.\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\ndf_clean = df[[\"gave\", \"treatment\"]].dropna()\n\nX = sm.add_constant(df_clean[\"treatment\"])\ny = df_clean[\"gave\"]\nprobit_model = sm.Probit(y, X).fit()\n\nprint(probit_model.summary())\n\nmfx = probit_model.get_margeff()\nprint(mfx.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Wed, 23 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        01:59:53   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n       Probit Marginal Effects       \n=====================================\nDep. Variable:                   gave\nMethod:                          dydx\nAt:                           overall\n==============================================================================\n                dy/dx    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\ntreatment      0.0043      0.001      3.104      0.002       0.002       0.007\n==============================================================================\n\n\nBased on the probit regression result, people in the treatment group are significantly more inclined to donate money.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\nfrom scipy import stats\n\nratio1 = df.query(\"ratio==1\")[\"gave\"]\nratio2 = df.query(\"ratio2==1\")[\"gave\"]\nratio3 = df.query(\"ratio3==1\")[\"gave\"]\n\n\n# t-test\ndef t_test(df1, df2):\n    mean_diff = df1.mean() - df2.mean()\n    var1 = df1.var(ddof=1)\n    var2 = df2.var(ddof=1)\n    se = np.sqrt(var1 / len(df1) + var2 / len(df2))\n    t_stat = mean_diff / se\n    ttest_result = round(t_stat, 2)\n    degree_of_freedom = (var1 / len(df1) + var1 / len(df2)) ** 2 / (\n        ((var1 / len(df1)) ** 2) / (len(df1) - 1)\n        + ((var1 / len(df2)) ** 2) / (len(df2) - 1)\n    )\n\n    p_value = stats.t.sf(np.abs(t_stat), degree_of_freedom) * 2\n\n    return ttest_result, round(p_value, 2)\n\n\nprint(\n    f\"1:1 vs 2:1: t-test {t_test(ratio2, ratio1)[0]}, p-value {t_test(ratio2, ratio1)[1]}\"\n)\nprint(\n    f\"2:1 vs 3:1: t-test {t_test(ratio3, ratio2)[0]}, p-value {t_test(ratio3, ratio2)[1]}\"\n)\nprint(\n    f\"1:1 vs 3:1: t-test {t_test(ratio3, ratio1)[0]}, p-value {t_test(ratio3, ratio1)[1]}\"\n)\n\n1:1 vs 2:1: t-test 0.97, p-value 0.33\n2:1 vs 3:1: t-test 0.05, p-value 0.96\n1:1 vs 3:1: t-test 1.02, p-value 0.31\n\n\nThe results show that there are no significant difference between match ratios, 1:1 vs 2:1, 2:1 vs 3:1, or 1:1 vs 3:1.\n\nX = df[[\"ratio2\", \"ratio3\"]]\nX = sm.add_constant(X)\ny = df[\"gave\"]\n\nmodel = sm.OLS(y, X).fit()\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     4.117\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):             0.0163\nTime:                        01:59:53   Log-Likelihood:                 26629.\nNo. Observations:               50083   AIC:                        -5.325e+04\nDf Residuals:                   50080   BIC:                        -5.323e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.0190      0.001     22.306      0.000       0.017       0.021\nratio2         0.0036      0.002      2.269      0.023       0.000       0.007\nratio3         0.0037      0.002      2.332      0.020       0.001       0.007\n==============================================================================\nOmnibus:                    59815.856   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317637.927\nSkew:                           6.741   Prob(JB):                         0.00\nKurtosis:                      46.443   Cond. No.                         3.16\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\nratio1_mean = df.query(\"(ratio2 == 0) & (ratio3 == 0)\")[\"gave\"].mean()\nratio2_mean = df.query(\"ratio2==1\")[\"gave\"].mean()\nratio3_mean = df.query(\"ratio3==1\")[\"gave\"].mean()\n\ndiff11_21 = ratio2_mean - ratio1_mean\ndiff21_31 = ratio3_mean - ratio2_mean\n\nprint(f\"2:1 - 1:1 = {diff11_21:.4f}\")\nprint(f\"3:1 - 2:1 = {diff21_31:.4f}\")\n\n2:1 - 1:1 = 0.0036\n3:1 - 2:1 = 0.0001\n\n\nWhen calculating the response rate directly from the data, the difference between the 2:1 and 1:1 match ratios is about 0.36, while the difference between 3:1 and 2:1 is only 0.01. These results are consistent with the coefficients from the OLS regression, where ratio2 and ratio3 have coefficients of 0.0036 and 0.0037 respectively.\nIn conclusion, increasing the match ratio from 1:1 to 2:1 appears to have a small positive effect on donation likelihood, but increasing the match ratio further to 3:1 shows no additional gain.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\nT-test\n\ntreat_amount = df.query(\"treatment == 1\")[\"amount\"]\ncontrol_amount = df.query(\"control == 1\")[\"amount\"]\nprint(\n    f\"t_stats: {t_test(treat_amount, control_amount)[0]:.2f}, p-value: {t_test(treat_amount, control_amount)[1]:.2f}\"\n)\n\nt_stats: 1.92, p-value: 0.06\n\n\nLinear Regression\n\nX = sm.add_constant(df[\"treatment\"])\ny = df[\"amount\"]\nmodel = sm.OLS(y, X, missing=\"drop\").fit()\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.461\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):             0.0628\nTime:                        01:59:54   Log-Likelihood:            -1.7946e+05\nNo. Observations:               50083   AIC:                         3.589e+05\nDf Residuals:                   50081   BIC:                         3.589e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.8133      0.067     12.063      0.000       0.681       0.945\ntreatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n==============================================================================\nOmnibus:                    96861.113   Durbin-Watson:                   2.008\nProb(Omnibus):                  0.000   Jarque-Bera (JB):        240735713.635\nSkew:                          15.297   Prob(JB):                         0.00\nKurtosis:                     341.269   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nWe conduct a t-test and a bivariate regression of the donation amount on treatment assignment. The results show that treatment group donors gave approximately $0.15 more on average than the control group, but the difference is small that the p-value wasn’t statistically significant, meaning that the impact is limited.\n\ntreat_amount_gave = df.query(\"treatment == 1 and gave==1\")[\"amount\"]\ncontrol_amount_gave = df.query(\"control == 1 and gave==1\")[\"amount\"]\nX = sm.add_constant(df.query(\"gave==1\")[\"treatment\"])\ny = df.query(\"gave==1\")[\"amount\"]\nmodel = sm.OLS(y, X, missing=\"drop\").fit()\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.561\nTime:                        01:59:54   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nWe then looked into the sample that made a donation and did the regression analysis o donation amount on treatment assignment. The coefficient on treatment is −1.67 with a p-value of 0.561, indicating no statistically significant difference in donation amounts between the treatment and control groups, suggesting that the treatment group only, on average, gave slightly less than the control group.\nHowever, the coefficient does not allow a causal interpretation because adding conditions on treatment behavior (donating) introduces potential selection bias.\n\nfig, ax = plt.subplots()\nbars = ax.bar(\n    [\"treat\", \"control\"],\n    [treat_amount_gave.mean(), control_amount_gave.mean()],\n    color=[\"skyblue\", \"orange\"],\n)\n\nfor bar in bars:\n    height = bar.get_height()\n    ax.annotate(\n        f\"${height:.2f}\",\n        xy=(bar.get_x() + bar.get_width() / 2, height),\n        xytext=(0, 2),\n        textcoords=\"offset points\",\n        ha=\"center\",\n        va=\"bottom\",\n    )\n\nax.set_ylabel(\"Average Donation Amount ($)\")\nax.set_title(\"Average Donation Amount\")\n\nplt.show()\n\n\n\n\n\n\n\n\nThe bar chart compares the average donation amounts between treatment and control groups, conditional on having donated. The control group gave slightly more on average ($45.54) than the treatment group ($43.87)."
  },
  {
    "objectID": "hw1_questions.html#simulation-experiment",
    "href": "hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\np_control = 0.018\np_treat = 0.022\nn_sim = 10_000\n\nnp.random.seed(100)\ncontrol_draw = np.random.binomial(1, p_control, n_sim)\ntreat_draw = np.random.binomial(1, p_treat, n_sim)\n\ndiff = treat_draw - control_draw\ncumulative_avg = np.cumsum(diff) / np.arange(1, n_sim + 1)\n\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label=\"Cumulative Avg of Difference: Treatment - Control\")\nplt.axhline(p_treat - p_control, color=\"red\", linestyle=\"--\", label=\"True Mean Diff\")\nplt.title(\"Simulation of Cumulative Average Difference\")\nplt.xlabel(\"Number of Simulations\")\nplt.ylabel(\"Cumulative Average\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nThe figure shows the cumulative average difference between treatment and control groups from a simulation. The average converges toward the true difference (0.004) as the number of simulations gets larger.\nThis illustrates the Law of Large Numbers: as the number of simulations increases, the observed mean gets closer to the expected (true) mean.\n\n\nCentral Limit Theorem\n\nsample_sizes = [50, 200, 500, 1000]\n\nfig, axs = plt.subplots(2, 2, figsize=(12, 8))\naxs = axs.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    diffs = []\n    np.random.seed(100)\n    for _ in range(n_sim):\n        c = np.random.binomial(1, p_control, n).mean()\n        t = np.random.binomial(1, p_treat, n).mean()\n        diffs.append(t - c)\n\n    axs[i].hist(diffs, bins=30, color=\"lightblue\", edgecolor=\"black\")\n    axs[i].axvline(0, color=\"red\", linestyle=\"--\", label=\"Zero Line\")\n    axs[i].axvline(np.mean(diffs), color=\"green\", linestyle=\"-\", label=\"Mean Diff\")\n    axs[i].set_title(f\"Sample size = {n}\")\n    axs[i].set_xlabel(\"Treatment - Control Mean Diff\")\n    axs[i].set_ylabel(\"Frequency\")\n    axs[i].legend()\n\nplt.suptitle(\"Central Limit Theorem: Distribution of Mean Differences\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nAs the sample size gets larger (50, 200, 500, 1,000), the distribution of average differences will be narrower, more symmetric, and closer to normal distribution.\nFor small samples (e.g., n = 50), the distribution is noisy and is closer to 0. As n becomes larger (e.g., n = 1,000), the distribution converges to normal and centers around the true effect (0.04)."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "Projects/project1/index.html",
    "href": "Projects/project1/index.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn the experiment, the authors collaborated with a nonprofit organization and conducted a large-scale field experiment involving over 50,000 prior donors. Each donor was randomly assigned to receive one of several types of direct-mail fundraising letters.\nThe control group received a standard letter with no match offer, while the treatment groups received a matching grant offer, where an anonymous donor pledged to match donations at a rate of 1:1, 2:1, or 3:1. Additionally, the letters varied in their presentation of the suggested donation amount and the total match cap ($25,000 / $50,000 / $100,000 / unstated).\nThe researchers then tracked each recipient’s response—specifically: • Whether they donated at all (gave) • How much they donated (amount)\nThis allowed the authors to examine whether matching grants increase donations, whether the size of the match ratio matters, and how the differences influence donor behavior.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "Projects/project1/index.html#introduction",
    "href": "Projects/project1/index.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn the experiment, the authors collaborated with a nonprofit organization and conducted a large-scale field experiment involving over 50,000 prior donors. Each donor was randomly assigned to receive one of several types of direct-mail fundraising letters.\nThe control group received a standard letter with no match offer, while the treatment groups received a matching grant offer, where an anonymous donor pledged to match donations at a rate of 1:1, 2:1, or 3:1. Additionally, the letters varied in their presentation of the suggested donation amount and the total match cap ($25,000 / $50,000 / $100,000 / unstated).\nThe researchers then tracked each recipient’s response—specifically: • Whether they donated at all (gave) • How much they donated (amount)\nThis allowed the authors to examine whether matching grants increase donations, whether the size of the match ratio matters, and how the differences influence donor behavior.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "Projects/project1/index.html#data",
    "href": "Projects/project1/index.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\nimport pandas as pd\n\ndf = pd.read_stata(\n    \"/Users/rebeccatseng/Downloads/Rebecca_marketing_analytics/data/karlan_list_2007.dta\",\n    iterator=False,\n)\ndf.head()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\n\n\n\ndf.describe()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio2\nratio3\nsize25\nsize50\nsize100\nsizeno\naskd1\naskd2\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\ncount\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n...\n49978.000000\n49978.000000\n48217.000000\n48047.000000\n48217.000000\n48221.000000\n48209.000000\n48214.000000\n48215.000000\n48217.000000\n\n\nmean\n0.666813\n0.333187\n0.222311\n0.222211\n0.166723\n0.166623\n0.166723\n0.166743\n0.222311\n0.222291\n...\n0.510245\n0.488715\n0.819599\n0.086710\n0.321694\n2.429012\n54815.700533\n0.669418\n0.391661\n0.871968\n\n\nstd\n0.471357\n0.471357\n0.415803\n0.415736\n0.372732\n0.372643\n0.372732\n0.372750\n0.415803\n0.415790\n...\n0.499900\n0.499878\n0.168561\n0.135868\n0.103039\n0.378115\n22027.316665\n0.193405\n0.186599\n0.258654\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.009418\n0.000000\n0.000000\n0.000000\n5000.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.755845\n0.014729\n0.258311\n2.210000\n39181.000000\n0.560222\n0.235647\n0.884929\n\n\n50%\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n0.000000\n0.872797\n0.036554\n0.305534\n2.440000\n50673.000000\n0.712296\n0.373744\n1.000000\n\n\n75%\n1.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n1.000000\n0.938827\n0.090882\n0.369132\n2.660000\n66005.000000\n0.816798\n0.530036\n1.000000\n\n\nmax\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n0.989622\n0.997544\n5.270000\n200001.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n8 rows × 48 columns\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nfrom sklearn import linear_model\nimport numpy as np\n\ntest_variables = [\"hpa\", \"mrm2\", \"freq\", \"years\", \"year5\", \"dormant\"]\n\n\ndef compare_ttest_regress(variable):\n\n    subset = df[[\"treatment\", variable]].dropna()\n    treat = subset[subset[\"treatment\"] == 1][variable]\n    control = subset[subset[\"treatment\"] == 0][variable]\n\n    # t-test\n    mean_diff = treat.mean() - control.mean()\n    var_treat = treat.var(ddof=1)\n    var_control = control.var(ddof=1)\n    se = np.sqrt(var_treat / len(treat) + var_control / len(control))\n    t_stat = mean_diff / se\n    ttest_result = round(t_stat, 2)\n\n    # regression\n    X = subset[\"treatment\"].values.reshape(-1, 1)\n    y = subset[variable].values\n    reg = linear_model.LinearRegression()\n    reg.fit(X, y)\n    reg_result = round(reg.coef_[0] / se, 2)\n\n    return ttest_result, reg_result\n\n\nresults = []\nfor v in test_variables:\n    results.append(\n        {\n            \"variable\": v,\n            \"t_test\": compare_ttest_regress(v)[0],\n            \"regress\": compare_ttest_regress(v)[1],\n        }\n    )\n\ndf_result = pd.DataFrame(results)\ndf_result\n\n\n\n\n\n\n\n\nvariable\nt_test\nregress\n\n\n\n\n0\nhpa\n0.97\n0.97\n\n\n1\nmrm2\n0.12\n0.12\n\n\n2\nfreq\n-0.11\n-0.11\n\n\n3\nyears\n-1.09\n-1.09\n\n\n4\nyear5\n-1.56\n-1.56\n\n\n5\ndormant\n0.17\n0.17"
  },
  {
    "objectID": "Projects/project1/index.html#experimental-results",
    "href": "Projects/project1/index.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nimport matplotlib.pyplot as plt\n\n\ndf_treat = df.query(\"treatment==1\")\ndf_control = df.query(\"control==1\")\ntreat_prop = df_treat[\"gave\"].value_counts(normalize=True)\ncontrol_prop = df_control[\"gave\"].value_counts(normalize=True)\n\nfig, ax = plt.subplots()\nbars = ax.bar(\n    [\"treat\", \"control\"],\n    [treat_prop[1] * 100, control_prop[1] * 100],\n    color=[\"skyblue\", \"orange\"],\n)\n\nfor bar in bars:\n    height = bar.get_height()\n    ax.annotate(\n        f\"{height:.1f}%\",\n        xy=(bar.get_x() + bar.get_width() / 2, height),\n        xytext=(0, 2),\n        textcoords=\"offset points\",\n        ha=\"center\",\n        va=\"bottom\",\n    )\n\n\n\n\n\n\n\n\n\ntreat = df[df[\"treatment\"] == 1][\"gave\"]\ncontrol = df[df[\"treatment\"] == 0][\"gave\"]\n# t-test\nmean_diff = treat.mean() - control.mean()\nvar_treat = treat.var(ddof=1)\nvar_control = control.var(ddof=1)\nse = np.sqrt(var_treat / len(treat) + var_control / len(control))\nt_stat = mean_diff / se\nttest_result = round(t_stat, 2)\nttest_result\n\nnp.float64(3.21)\n\n\nSince the t-test result is so large, we can conclude that the treatment group is significantly more willing to donate than the control group.\n\n# regression\nX = df[\"treatment\"].values.reshape(-1, 1)\ny = df[\"gave\"].values\nreg = linear_model.LinearRegression()\nreg.fit(X, y)\nreg_result = round(reg.coef_[0] / se, 2)\nreg_result\n\nnp.float64(3.21)\n\n\nAccording to the linear regression model, the coefficient is so big that we can conclude that the treatment group is more likely to donate than the control group.\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\ndf_clean = df[[\"gave\", \"treatment\"]].dropna()\n\nX = sm.add_constant(df_clean[\"treatment\"])\ny = df_clean[\"gave\"]\nprobit_model = sm.Probit(y, X).fit()\n\nprint(probit_model.summary())\n\nmfx = probit_model.get_margeff()\nprint(mfx.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Wed, 23 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        01:59:57   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n       Probit Marginal Effects       \n=====================================\nDep. Variable:                   gave\nMethod:                          dydx\nAt:                           overall\n==============================================================================\n                dy/dx    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\ntreatment      0.0043      0.001      3.104      0.002       0.002       0.007\n==============================================================================\n\n\nBased on the probit regression result, people in the treatment group are significantly more inclined to donate money.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\nfrom scipy import stats\n\nratio1 = df.query(\"ratio==1\")[\"gave\"]\nratio2 = df.query(\"ratio2==1\")[\"gave\"]\nratio3 = df.query(\"ratio3==1\")[\"gave\"]\n\n\n# t-test\ndef t_test(df1, df2):\n    mean_diff = df1.mean() - df2.mean()\n    var1 = df1.var(ddof=1)\n    var2 = df2.var(ddof=1)\n    se = np.sqrt(var1 / len(df1) + var2 / len(df2))\n    t_stat = mean_diff / se\n    ttest_result = round(t_stat, 2)\n    degree_of_freedom = (var1 / len(df1) + var1 / len(df2)) ** 2 / (\n        ((var1 / len(df1)) ** 2) / (len(df1) - 1)\n        + ((var1 / len(df2)) ** 2) / (len(df2) - 1)\n    )\n\n    p_value = stats.t.sf(np.abs(t_stat), degree_of_freedom) * 2\n\n    return ttest_result, round(p_value, 2)\n\n\nprint(\n    f\"1:1 vs 2:1: t-test {t_test(ratio2, ratio1)[0]}, p-value {t_test(ratio2, ratio1)[1]}\"\n)\nprint(\n    f\"2:1 vs 3:1: t-test {t_test(ratio3, ratio2)[0]}, p-value {t_test(ratio3, ratio2)[1]}\"\n)\nprint(\n    f\"1:1 vs 3:1: t-test {t_test(ratio3, ratio1)[0]}, p-value {t_test(ratio3, ratio1)[1]}\"\n)\n\n1:1 vs 2:1: t-test 0.97, p-value 0.33\n2:1 vs 3:1: t-test 0.05, p-value 0.96\n1:1 vs 3:1: t-test 1.02, p-value 0.31\n\n\nThe results show that there are no significant difference between match ratios, 1:1 vs 2:1, 2:1 vs 3:1, or 1:1 vs 3:1.\n\nX = df[[\"ratio2\", \"ratio3\"]]\nX = sm.add_constant(X)\ny = df[\"gave\"]\n\nmodel = sm.OLS(y, X).fit()\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     4.117\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):             0.0163\nTime:                        01:59:57   Log-Likelihood:                 26629.\nNo. Observations:               50083   AIC:                        -5.325e+04\nDf Residuals:                   50080   BIC:                        -5.323e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.0190      0.001     22.306      0.000       0.017       0.021\nratio2         0.0036      0.002      2.269      0.023       0.000       0.007\nratio3         0.0037      0.002      2.332      0.020       0.001       0.007\n==============================================================================\nOmnibus:                    59815.856   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317637.927\nSkew:                           6.741   Prob(JB):                         0.00\nKurtosis:                      46.443   Cond. No.                         3.16\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\nratio1_mean = df.query(\"(ratio2 == 0) & (ratio3 == 0)\")[\"gave\"].mean()\nratio2_mean = df.query(\"ratio2==1\")[\"gave\"].mean()\nratio3_mean = df.query(\"ratio3==1\")[\"gave\"].mean()\n\ndiff11_21 = ratio2_mean - ratio1_mean\ndiff21_31 = ratio3_mean - ratio2_mean\n\nprint(f\"2:1 - 1:1 = {diff11_21:.4f}\")\nprint(f\"3:1 - 2:1 = {diff21_31:.4f}\")\n\n2:1 - 1:1 = 0.0036\n3:1 - 2:1 = 0.0001\n\n\nWhen calculating the response rate directly from the data, the difference between the 2:1 and 1:1 match ratios is about 0.36, while the difference between 3:1 and 2:1 is only 0.01. These results are consistent with the coefficients from the OLS regression, where ratio2 and ratio3 have coefficients of 0.0036 and 0.0037 respectively.\nIn conclusion, increasing the match ratio from 1:1 to 2:1 appears to have a small positive effect on donation likelihood, but increasing the match ratio further to 3:1 shows no additional gain.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\nT-test\n\ntreat_amount = df.query(\"treatment == 1\")[\"amount\"]\ncontrol_amount = df.query(\"control == 1\")[\"amount\"]\nprint(\n    f\"t_stats: {t_test(treat_amount, control_amount)[0]:.2f}, p-value: {t_test(treat_amount, control_amount)[1]:.2f}\"\n)\n\nt_stats: 1.92, p-value: 0.06\n\n\nLinear Regression\n\nX = sm.add_constant(df[\"treatment\"])\ny = df[\"amount\"]\nmodel = sm.OLS(y, X, missing=\"drop\").fit()\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.461\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):             0.0628\nTime:                        01:59:58   Log-Likelihood:            -1.7946e+05\nNo. Observations:               50083   AIC:                         3.589e+05\nDf Residuals:                   50081   BIC:                         3.589e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.8133      0.067     12.063      0.000       0.681       0.945\ntreatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n==============================================================================\nOmnibus:                    96861.113   Durbin-Watson:                   2.008\nProb(Omnibus):                  0.000   Jarque-Bera (JB):        240735713.635\nSkew:                          15.297   Prob(JB):                         0.00\nKurtosis:                     341.269   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nWe conduct a t-test and a bivariate regression of the donation amount on treatment assignment. The results show that treatment group donors gave approximately $0.15 more on average than the control group, but the difference is small that the p-value wasn’t statistically significant, meaning that the impact is limited.\n\ntreat_amount_gave = df.query(\"treatment == 1 and gave==1\")[\"amount\"]\ncontrol_amount_gave = df.query(\"control == 1 and gave==1\")[\"amount\"]\nX = sm.add_constant(df.query(\"gave==1\")[\"treatment\"])\ny = df.query(\"gave==1\")[\"amount\"]\nmodel = sm.OLS(y, X, missing=\"drop\").fit()\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.561\nTime:                        01:59:58   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nWe then looked into the sample that made a donation and did the regression analysis o donation amount on treatment assignment. The coefficient on treatment is −1.67 with a p-value of 0.561, indicating no statistically significant difference in donation amounts between the treatment and control groups, suggesting that the treatment group only, on average, gave slightly less than the control group.\nHowever, the coefficient does not allow a causal interpretation because adding conditions on treatment behavior (donating) introduces potential selection bias.\n\nfig, ax = plt.subplots()\nbars = ax.bar(\n    [\"treat\", \"control\"],\n    [treat_amount_gave.mean(), control_amount_gave.mean()],\n    color=[\"skyblue\", \"orange\"],\n)\n\nfor bar in bars:\n    height = bar.get_height()\n    ax.annotate(\n        f\"${height:.2f}\",\n        xy=(bar.get_x() + bar.get_width() / 2, height),\n        xytext=(0, 2),\n        textcoords=\"offset points\",\n        ha=\"center\",\n        va=\"bottom\",\n    )\n\nax.set_ylabel(\"Average Donation Amount ($)\")\nax.set_title(\"Average Donation Amount\")\n\nplt.show()\n\n\n\n\n\n\n\n\nThe bar chart compares the average donation amounts between treatment and control groups, conditional on having donated. The control group gave slightly more on average ($45.54) than the treatment group ($43.87)."
  },
  {
    "objectID": "Projects/project1/index.html#simulation-experiment",
    "href": "Projects/project1/index.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\np_control = 0.018\np_treat = 0.022\nn_sim = 10_000\n\nnp.random.seed(100)\ncontrol_draw = np.random.binomial(1, p_control, n_sim)\ntreat_draw = np.random.binomial(1, p_treat, n_sim)\n\ndiff = treat_draw - control_draw\ncumulative_avg = np.cumsum(diff) / np.arange(1, n_sim + 1)\n\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label=\"Cumulative Avg of Difference: Treatment - Control\")\nplt.axhline(p_treat - p_control, color=\"red\", linestyle=\"--\", label=\"True Mean Diff\")\nplt.title(\"Simulation of Cumulative Average Difference\")\nplt.xlabel(\"Number of Simulations\")\nplt.ylabel(\"Cumulative Average\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nThe figure shows the cumulative average difference between treatment and control groups from a simulation. The average converges toward the true difference (0.004) as the number of simulations gets larger.\nThis illustrates the Law of Large Numbers: as the number of simulations increases, the observed mean gets closer to the expected (true) mean.\n\n\nCentral Limit Theorem\n\nsample_sizes = [50, 200, 500, 1000]\n\nfig, axs = plt.subplots(2, 2, figsize=(12, 8))\naxs = axs.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    diffs = []\n    np.random.seed(100)\n    for _ in range(n_sim):\n        c = np.random.binomial(1, p_control, n).mean()\n        t = np.random.binomial(1, p_treat, n).mean()\n        diffs.append(t - c)\n\n    axs[i].hist(diffs, bins=30, color=\"lightblue\", edgecolor=\"black\")\n    axs[i].axvline(0, color=\"red\", linestyle=\"--\", label=\"Zero Line\")\n    axs[i].axvline(np.mean(diffs), color=\"green\", linestyle=\"-\", label=\"Mean Diff\")\n    axs[i].set_title(f\"Sample size = {n}\")\n    axs[i].set_xlabel(\"Treatment - Control Mean Diff\")\n    axs[i].set_ylabel(\"Frequency\")\n    axs[i].legend()\n\nplt.suptitle(\"Central Limit Theorem: Distribution of Mean Differences\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nAs the sample size gets larger (50, 200, 500, 1,000), the distribution of average differences will be narrower, more symmetric, and closer to normal distribution.\nFor small samples (e.g., n = 50), the distribution is noisy and is closer to 0. As n becomes larger (e.g., n = 1,000), the distribution converges to normal and centers around the true effect (0.04)."
  },
  {
    "objectID": "Projects.html",
    "href": "Projects.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\n\n\nKuan-Ling (Rebecca) Tseng\n\n\nApr 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  }
]