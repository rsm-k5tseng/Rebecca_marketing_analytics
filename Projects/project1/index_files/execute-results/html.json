{
  "hash": "2eebc5169b49fc9133dea374776fd9ab",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"A Replication of Karlan and List (2007)\"\nauthor: \"Kuan-Ling (Rebecca) Tseng\"\ndate: today\ncallout-appearance: minimal # this hides the blue \"i\" icon on .callout-notes\n---\n\n\n\n## Introduction\n\nDean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the _American Economic Review_ in 2007. The article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action as part of [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2).\n\nIn the experiment, the authors collaborated with a nonprofit organization and conducted a large-scale field experiment involving over 50,000 prior donors. Each donor was randomly assigned to receive one of several types of direct-mail fundraising letters.\n\nThe control group received a standard letter with no match offer, while the treatment groups received a matching grant offer, where an anonymous donor pledged to match donations at a rate of 1:1, 2:1, or 3:1. Additionally, the letters varied in their presentation of the suggested donation amount and the total match cap ($25,000 / $50,000 / $100,000 / unstated).\n\nThe researchers then tracked each recipient’s response—specifically:\n•\tWhether they donated at all (gave)\n•\tHow much they donated (amount)\n\nThis allowed the authors to examine whether matching grants increase donations, whether the size of the match ratio matters, and how the differences influence donor behavior.\n\nThis project seeks to replicate their results.\n\n## Data\n\n### Description\n\n::: {#431e98a5 .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\n\ndf = pd.read_stata(\n    \"/Users/rebeccatseng/Downloads/Rebecca_marketing_analytics/data/karlan_list_2007.dta\",\n    iterator=False,\n)\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>treatment</th>\n      <th>control</th>\n      <th>ratio</th>\n      <th>ratio2</th>\n      <th>ratio3</th>\n      <th>size</th>\n      <th>size25</th>\n      <th>size50</th>\n      <th>size100</th>\n      <th>sizeno</th>\n      <th>...</th>\n      <th>redcty</th>\n      <th>bluecty</th>\n      <th>pwhite</th>\n      <th>pblack</th>\n      <th>page18_39</th>\n      <th>ave_hh_sz</th>\n      <th>median_hhincome</th>\n      <th>powner</th>\n      <th>psch_atlstba</th>\n      <th>pop_propurban</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>Control</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Control</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.446493</td>\n      <td>0.527769</td>\n      <td>0.317591</td>\n      <td>2.10</td>\n      <td>28517.0</td>\n      <td>0.499807</td>\n      <td>0.324528</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>Control</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Control</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>$100,000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.935706</td>\n      <td>0.011948</td>\n      <td>0.276128</td>\n      <td>2.48</td>\n      <td>51175.0</td>\n      <td>0.721941</td>\n      <td>0.192668</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Unstated</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.888331</td>\n      <td>0.010760</td>\n      <td>0.279412</td>\n      <td>2.65</td>\n      <td>79269.0</td>\n      <td>0.920431</td>\n      <td>0.412142</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>$50,000</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.759014</td>\n      <td>0.127421</td>\n      <td>0.442389</td>\n      <td>1.85</td>\n      <td>40908.0</td>\n      <td>0.416072</td>\n      <td>0.439965</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 51 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {#a46be3a0 .cell execution_count=2}\n``` {.python .cell-code}\ndf.describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>treatment</th>\n      <th>control</th>\n      <th>ratio2</th>\n      <th>ratio3</th>\n      <th>size25</th>\n      <th>size50</th>\n      <th>size100</th>\n      <th>sizeno</th>\n      <th>askd1</th>\n      <th>askd2</th>\n      <th>...</th>\n      <th>redcty</th>\n      <th>bluecty</th>\n      <th>pwhite</th>\n      <th>pblack</th>\n      <th>page18_39</th>\n      <th>ave_hh_sz</th>\n      <th>median_hhincome</th>\n      <th>powner</th>\n      <th>psch_atlstba</th>\n      <th>pop_propurban</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>50083.000000</td>\n      <td>50083.000000</td>\n      <td>50083.000000</td>\n      <td>50083.000000</td>\n      <td>50083.000000</td>\n      <td>50083.000000</td>\n      <td>50083.000000</td>\n      <td>50083.000000</td>\n      <td>50083.000000</td>\n      <td>50083.000000</td>\n      <td>...</td>\n      <td>49978.000000</td>\n      <td>49978.000000</td>\n      <td>48217.000000</td>\n      <td>48047.000000</td>\n      <td>48217.000000</td>\n      <td>48221.000000</td>\n      <td>48209.000000</td>\n      <td>48214.000000</td>\n      <td>48215.000000</td>\n      <td>48217.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.666813</td>\n      <td>0.333187</td>\n      <td>0.222311</td>\n      <td>0.222211</td>\n      <td>0.166723</td>\n      <td>0.166623</td>\n      <td>0.166723</td>\n      <td>0.166743</td>\n      <td>0.222311</td>\n      <td>0.222291</td>\n      <td>...</td>\n      <td>0.510245</td>\n      <td>0.488715</td>\n      <td>0.819599</td>\n      <td>0.086710</td>\n      <td>0.321694</td>\n      <td>2.429012</td>\n      <td>54815.700533</td>\n      <td>0.669418</td>\n      <td>0.391661</td>\n      <td>0.871968</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.471357</td>\n      <td>0.471357</td>\n      <td>0.415803</td>\n      <td>0.415736</td>\n      <td>0.372732</td>\n      <td>0.372643</td>\n      <td>0.372732</td>\n      <td>0.372750</td>\n      <td>0.415803</td>\n      <td>0.415790</td>\n      <td>...</td>\n      <td>0.499900</td>\n      <td>0.499878</td>\n      <td>0.168561</td>\n      <td>0.135868</td>\n      <td>0.103039</td>\n      <td>0.378115</td>\n      <td>22027.316665</td>\n      <td>0.193405</td>\n      <td>0.186599</td>\n      <td>0.258654</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.009418</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5000.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.755845</td>\n      <td>0.014729</td>\n      <td>0.258311</td>\n      <td>2.210000</td>\n      <td>39181.000000</td>\n      <td>0.560222</td>\n      <td>0.235647</td>\n      <td>0.884929</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.872797</td>\n      <td>0.036554</td>\n      <td>0.305534</td>\n      <td>2.440000</td>\n      <td>50673.000000</td>\n      <td>0.712296</td>\n      <td>0.373744</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.938827</td>\n      <td>0.090882</td>\n      <td>0.369132</td>\n      <td>2.660000</td>\n      <td>66005.000000</td>\n      <td>0.816798</td>\n      <td>0.530036</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.989622</td>\n      <td>0.997544</td>\n      <td>5.270000</td>\n      <td>200001.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 48 columns</p>\n</div>\n```\n:::\n:::\n\n\n:::: {.callout-note collapse=\"true\"}\n### Variable Definitions\n\n| Variable             | Description                                                         |\n|----------------------|---------------------------------------------------------------------|\n| `treatment`          | Treatment                                                           |\n| `control`            | Control                                                             |\n| `ratio`              | Match ratio                                                         |\n| `ratio2`             | 2:1 match ratio                                                     |\n| `ratio3`             | 3:1 match ratio                                                     |\n| `size`               | Match threshold                                                     |\n| `size25`             | \\$25,000 match threshold                                            |\n| `size50`             | \\$50,000 match threshold                                            |\n| `size100`            | \\$100,000 match threshold                                           |\n| `sizeno`             | Unstated match threshold                                            |\n| `ask`                | Suggested donation amount                                           |\n| `askd1`              | Suggested donation was highest previous contribution                |\n| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |\n| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |\n| `ask1`               | Highest previous contribution (for suggestion)                      |\n| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |\n| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |\n| `amount`             | Dollars given                                                       |\n| `gave`               | Gave anything                                                       |\n| `amountchange`       | Change in amount given                                              |\n| `hpa`                | Highest previous contribution                                       |\n| `ltmedmra`           | Small prior donor: last gift was less than median \\$35              |\n| `freq`               | Number of prior donations                                           |\n| `years`              | Number of years since initial donation                              |\n| `year5`              | At least 5 years since initial donation                             |\n| `mrm2`               | Number of months since last donation                                |\n| `dormant`            | Already donated in 2005                                             |\n| `female`             | Female                                                              |\n| `couple`             | Couple                                                              |\n| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |\n| `nonlit`             | Nonlitigation                                                       |\n| `cases`              | Court cases from state in 2004-5 in which organization was involved |\n| `statecnt`           | Percent of sample from state                                        |\n| `stateresponse`      | Proportion of sample from the state who gave                        |\n| `stateresponset`     | Proportion of treated sample from the state who gave                |\n| `stateresponsec`     | Proportion of control sample from the state who gave                |\n| `stateresponsetminc` | stateresponset - stateresponsec                                     |\n| `perbush`            | State vote share for Bush                                           |\n| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |\n| `red0`               | Red state                                                           |\n| `blue0`              | Blue state                                                          |\n| `redcty`             | Red county                                                          |\n| `bluecty`            | Blue county                                                         |\n| `pwhite`             | Proportion white within zip code                                    |\n| `pblack`             | Proportion black within zip code                                    |\n| `page18_39`          | Proportion age 18-39 within zip code                                |\n| `ave_hh_sz`          | Average household size within zip code                              |\n| `median_hhincome`    | Median household income within zip code                             |\n| `powner`             | Proportion house owner within zip code                              |\n| `psch_atlstba`       | Proportion who finished college within zip code                     |\n| `pop_propurban`      | Proportion of population urban within zip code                      |\n\n::::\n\n\n### Balance Test \n\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\n::: {#dcc158c4 .cell execution_count=3}\n``` {.python .cell-code}\nfrom sklearn import linear_model\nimport numpy as np\n\ntest_variables = [\"hpa\", \"mrm2\", \"freq\", \"years\", \"year5\", \"dormant\"]\n\n\ndef compare_ttest_regress(variable):\n\n    subset = df[[\"treatment\", variable]].dropna()\n    treat = subset[subset[\"treatment\"] == 1][variable]\n    control = subset[subset[\"treatment\"] == 0][variable]\n\n    # t-test\n    mean_diff = treat.mean() - control.mean()\n    var_treat = treat.var(ddof=1)\n    var_control = control.var(ddof=1)\n    se = np.sqrt(var_treat / len(treat) + var_control / len(control))\n    t_stat = mean_diff / se\n    ttest_result = round(t_stat, 2)\n\n    # regression\n    X = subset[\"treatment\"].values.reshape(-1, 1)\n    y = subset[variable].values\n    reg = linear_model.LinearRegression()\n    reg.fit(X, y)\n    reg_result = round(reg.coef_[0] / se, 2)\n\n    return ttest_result, reg_result\n\n\nresults = []\nfor v in test_variables:\n    results.append(\n        {\n            \"variable\": v,\n            \"t_test\": compare_ttest_regress(v)[0],\n            \"regress\": compare_ttest_regress(v)[1],\n        }\n    )\n\ndf_result = pd.DataFrame(results)\ndf_result\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>variable</th>\n      <th>t_test</th>\n      <th>regress</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>hpa</td>\n      <td>0.97</td>\n      <td>0.97</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mrm2</td>\n      <td>0.12</td>\n      <td>0.12</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>freq</td>\n      <td>-0.11</td>\n      <td>-0.11</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>years</td>\n      <td>-1.09</td>\n      <td>-1.09</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>year5</td>\n      <td>-1.56</td>\n      <td>-1.56</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>dormant</td>\n      <td>0.17</td>\n      <td>0.17</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Experimental Results\n\n### Charitable Contribution Made\n\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation. \n\n::: {#a6117b5a .cell execution_count=4}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\n\n\ndf_treat = df.query(\"treatment==1\")\ndf_control = df.query(\"control==1\")\ntreat_prop = df_treat[\"gave\"].value_counts(normalize=True)\ncontrol_prop = df_control[\"gave\"].value_counts(normalize=True)\n\nfig, ax = plt.subplots()\nbars = ax.bar(\n    [\"treat\", \"control\"],\n    [treat_prop[1] * 100, control_prop[1] * 100],\n    color=[\"skyblue\", \"orange\"],\n)\n\nfor bar in bars:\n    height = bar.get_height()\n    ax.annotate(\n        f\"{height:.1f}%\",\n        xy=(bar.get_x() + bar.get_width() / 2, height),\n        xytext=(0, 2),\n        textcoords=\"offset points\",\n        ha=\"center\",\n        va=\"bottom\",\n    )\n\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-1.png){width=571 height=411}\n:::\n:::\n\n\n::: {#f9782e4f .cell execution_count=5}\n``` {.python .cell-code}\ntreat = df[df[\"treatment\"] == 1][\"gave\"]\ncontrol = df[df[\"treatment\"] == 0][\"gave\"]\n# t-test\nmean_diff = treat.mean() - control.mean()\nvar_treat = treat.var(ddof=1)\nvar_control = control.var(ddof=1)\nse = np.sqrt(var_treat / len(treat) + var_control / len(control))\nt_stat = mean_diff / se\nttest_result = round(t_stat, 2)\nttest_result\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\nnp.float64(3.21)\n```\n:::\n:::\n\n\nSince the t-test result is so large, we can conclude that the treatment group is significantly more willing to donate than the control group.\n\n::: {#8ad1020f .cell execution_count=6}\n``` {.python .cell-code}\n# regression\nX = df[\"treatment\"].values.reshape(-1, 1)\ny = df[\"gave\"].values\nreg = linear_model.LinearRegression()\nreg.fit(X, y)\nreg_result = round(reg.coef_[0] / se, 2)\nreg_result\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\nnp.float64(3.21)\n```\n:::\n:::\n\n\nAccording to the linear regression model, the coefficient is so big that we can conclude that the treatment group is more likely to donate than the control group.\n\n::: {#58fc82a6 .cell execution_count=7}\n``` {.python .cell-code}\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\ndf_clean = df[[\"gave\", \"treatment\"]].dropna()\n\nX = sm.add_constant(df_clean[\"treatment\"])\ny = df_clean[\"gave\"]\nprobit_model = sm.Probit(y, X).fit()\n\nprint(probit_model.summary())\n\nmfx = probit_model.get_margeff()\nprint(mfx.summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Wed, 23 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        01:52:52   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n       Probit Marginal Effects       \n=====================================\nDep. Variable:                   gave\nMethod:                          dydx\nAt:                           overall\n==============================================================================\n                dy/dx    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\ntreatment      0.0043      0.001      3.104      0.002       0.002       0.007\n==============================================================================\n```\n:::\n:::\n\n\nBased on the probit regression result, people in the treatment group are significantly more inclined to donate money.\n\n### Differences between Match Rates\n\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n::: {#b9cefc0b .cell execution_count=8}\n``` {.python .cell-code}\nfrom scipy import stats\n\nratio1 = df.query(\"ratio==1\")[\"gave\"]\nratio2 = df.query(\"ratio2==1\")[\"gave\"]\nratio3 = df.query(\"ratio3==1\")[\"gave\"]\n\n\n# t-test\ndef t_test(df1, df2):\n    mean_diff = df1.mean() - df2.mean()\n    var1 = df1.var(ddof=1)\n    var2 = df2.var(ddof=1)\n    se = np.sqrt(var1 / len(df1) + var2 / len(df2))\n    t_stat = mean_diff / se\n    ttest_result = round(t_stat, 2)\n    degree_of_freedom = (var1 / len(df1) + var1 / len(df2)) ** 2 / (\n        ((var1 / len(df1)) ** 2) / (len(df1) - 1)\n        + ((var1 / len(df2)) ** 2) / (len(df2) - 1)\n    )\n\n    p_value = stats.t.sf(np.abs(t_stat), degree_of_freedom) * 2\n\n    return ttest_result, round(p_value, 2)\n\n\nprint(\n    f\"1:1 vs 2:1: t-test {t_test(ratio2, ratio1)[0]}, p-value {t_test(ratio2, ratio1)[1]}\"\n)\nprint(\n    f\"2:1 vs 3:1: t-test {t_test(ratio3, ratio2)[0]}, p-value {t_test(ratio3, ratio2)[1]}\"\n)\nprint(\n    f\"1:1 vs 3:1: t-test {t_test(ratio3, ratio1)[0]}, p-value {t_test(ratio3, ratio1)[1]}\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1:1 vs 2:1: t-test 0.97, p-value 0.33\n2:1 vs 3:1: t-test 0.05, p-value 0.96\n1:1 vs 3:1: t-test 1.02, p-value 0.31\n```\n:::\n:::\n\n\nThe results show that there are no significant difference between match ratios, 1:1 vs 2:1, 2:1 vs 3:1, or 1:1 vs 3:1.\n\n::: {#7a5ac44e .cell execution_count=9}\n``` {.python .cell-code}\nX = df[[\"ratio2\", \"ratio3\"]]\nX = sm.add_constant(X)\ny = df[\"gave\"]\n\nmodel = sm.OLS(y, X).fit()\nprint(model.summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     4.117\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):             0.0163\nTime:                        01:52:52   Log-Likelihood:                 26629.\nNo. Observations:               50083   AIC:                        -5.325e+04\nDf Residuals:                   50080   BIC:                        -5.323e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.0190      0.001     22.306      0.000       0.017       0.021\nratio2         0.0036      0.002      2.269      0.023       0.000       0.007\nratio3         0.0037      0.002      2.332      0.020       0.001       0.007\n==============================================================================\nOmnibus:                    59815.856   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317637.927\nSkew:                           6.741   Prob(JB):                         0.00\nKurtosis:                      46.443   Cond. No.                         3.16\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n```\n:::\n:::\n\n\n::: {#5a8cc543 .cell execution_count=10}\n``` {.python .cell-code}\nratio1_mean = df.query(\"(ratio2 == 0) & (ratio3 == 0)\")[\"gave\"].mean()\nratio2_mean = df.query(\"ratio2==1\")[\"gave\"].mean()\nratio3_mean = df.query(\"ratio3==1\")[\"gave\"].mean()\n\ndiff11_21 = ratio2_mean - ratio1_mean\ndiff21_31 = ratio3_mean - ratio2_mean\n\nprint(f\"2:1 - 1:1 = {diff11_21:.4f}\")\nprint(f\"3:1 - 2:1 = {diff21_31:.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n2:1 - 1:1 = 0.0036\n3:1 - 2:1 = 0.0001\n```\n:::\n:::\n\n\nWhen calculating the response rate directly from the data, the difference between the 2:1 and 1:1 match ratios is about 0.36, while the difference between 3:1 and 2:1 is only 0.01. These results are consistent with the coefficients from the OLS regression, where ratio2 and ratio3 have coefficients of 0.0036 and 0.0037 respectively.\n\nIn conclusion, increasing the match ratio from 1:1 to 2:1 appears to have a small positive effect on donation likelihood, but increasing the match ratio further to 3:1 shows no additional gain. \n\n### Size of Charitable Contribution\n\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\nT-test\n\n::: {#b16cf3fe .cell execution_count=11}\n``` {.python .cell-code}\ntreat_amount = df.query(\"treatment == 1\")[\"amount\"]\ncontrol_amount = df.query(\"control == 1\")[\"amount\"]\nprint(\n    f\"t_stats: {t_test(treat_amount, control_amount)[0]:.2f}, p-value: {t_test(treat_amount, control_amount)[1]:.2f}\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nt_stats: 1.92, p-value: 0.06\n```\n:::\n:::\n\n\nLinear Regression\n\n::: {#9c9444e9 .cell execution_count=12}\n``` {.python .cell-code}\nX = sm.add_constant(df[\"treatment\"])\ny = df[\"amount\"]\nmodel = sm.OLS(y, X, missing=\"drop\").fit()\nprint(model.summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.461\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):             0.0628\nTime:                        01:52:52   Log-Likelihood:            -1.7946e+05\nNo. Observations:               50083   AIC:                         3.589e+05\nDf Residuals:                   50081   BIC:                         3.589e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.8133      0.067     12.063      0.000       0.681       0.945\ntreatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n==============================================================================\nOmnibus:                    96861.113   Durbin-Watson:                   2.008\nProb(Omnibus):                  0.000   Jarque-Bera (JB):        240735713.635\nSkew:                          15.297   Prob(JB):                         0.00\nKurtosis:                     341.269   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n```\n:::\n:::\n\n\nWe conduct a t-test and a bivariate regression of the donation amount on treatment assignment. The results show that treatment group donors gave approximately $0.15 more on average than the control group, but the difference is small that the p-value wasn't statistically significant, meaning that the impact is limited. \n\n::: {#d6d30441 .cell execution_count=13}\n``` {.python .cell-code}\ntreat_amount_gave = df.query(\"treatment == 1 and gave==1\")[\"amount\"]\ncontrol_amount_gave = df.query(\"control == 1 and gave==1\")[\"amount\"]\nX = sm.add_constant(df.query(\"gave==1\")[\"treatment\"])\ny = df.query(\"gave==1\")[\"amount\"]\nmodel = sm.OLS(y, X, missing=\"drop\").fit()\nprint(model.summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.561\nTime:                        01:52:52   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n```\n:::\n:::\n\n\nWe then looked into the sample that made a donation and did the regression analysis o donation amount on treatment assignment. The coefficient on treatment is −1.67 with a p-value of 0.561, indicating no statistically significant difference in donation amounts between the treatment and control groups, suggesting that the treatment group only, on average, gave slightly less than the control group.\n\nHowever, the coefficient does not allow a causal interpretation because adding conditions on treatment behavior (donating) introduces potential selection bias.\n\n::: {#f8802742 .cell execution_count=14}\n``` {.python .cell-code}\nfig, ax = plt.subplots()\nbars = ax.bar(\n    [\"treat\", \"control\"],\n    [treat_amount_gave.mean(), control_amount_gave.mean()],\n    color=[\"skyblue\", \"orange\"],\n)\n\nfor bar in bars:\n    height = bar.get_height()\n    ax.annotate(\n        f\"${height:.2f}\",\n        xy=(bar.get_x() + bar.get_width() / 2, height),\n        xytext=(0, 2),\n        textcoords=\"offset points\",\n        ha=\"center\",\n        va=\"bottom\",\n    )\n\nax.set_ylabel(\"Average Donation Amount ($)\")\nax.set_title(\"Average Donation Amount\")\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-15-output-1.png){width=585 height=431}\n:::\n:::\n\n\nThe bar chart compares the average donation amounts between treatment and control groups, conditional on having donated. The control group gave slightly more on average ($45.54) than the treatment group ($43.87).\n\n\n## Simulation Experiment\n\nAs a reminder of how the t-statistic \"works,\" in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\n\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made. \n\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size  is Bernoulli with probability p=0.022 that a donation is made.\n\n### Law of Large Numbers\n\n::: {#99d65953 .cell execution_count=15}\n``` {.python .cell-code}\np_control = 0.018\np_treat = 0.022\nn_sim = 10_000\n\nnp.random.seed(100)\ncontrol_draw = np.random.binomial(1, p_control, n_sim)\ntreat_draw = np.random.binomial(1, p_treat, n_sim)\n\ndiff = treat_draw - control_draw\ncumulative_avg = np.cumsum(diff) / np.arange(1, n_sim + 1)\n\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label=\"Cumulative Avg of Difference: Treatment - Control\")\nplt.axhline(p_treat - p_control, color=\"red\", linestyle=\"--\", label=\"True Mean Diff\")\nplt.title(\"Simulation of Cumulative Average Difference\")\nplt.xlabel(\"Number of Simulations\")\nplt.ylabel(\"Cumulative Average\")\nplt.legend()\nplt.grid(True)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-16-output-1.png){width=812 height=449}\n:::\n:::\n\n\nThe figure shows the cumulative average difference between treatment and control groups from a simulation. The average converges toward the true difference (0.004) as the number of simulations gets larger.\n\nThis illustrates the Law of Large Numbers: as the number of simulations increases, the observed mean gets closer to the expected (true) mean.\n\n### Central Limit Theorem\n\n::: {#e77d3d8f .cell execution_count=16}\n``` {.python .cell-code}\nsample_sizes = [50, 200, 500, 1000]\n\nfig, axs = plt.subplots(2, 2, figsize=(12, 8))\naxs = axs.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    diffs = []\n    np.random.seed(100)\n    for _ in range(n_sim):\n        c = np.random.binomial(1, p_control, n).mean()\n        t = np.random.binomial(1, p_treat, n).mean()\n        diffs.append(t - c)\n\n    axs[i].hist(diffs, bins=30, color=\"lightblue\", edgecolor=\"black\")\n    axs[i].axvline(0, color=\"red\", linestyle=\"--\", label=\"Zero Line\")\n    axs[i].axvline(np.mean(diffs), color=\"green\", linestyle=\"-\", label=\"Mean Diff\")\n    axs[i].set_title(f\"Sample size = {n}\")\n    axs[i].set_xlabel(\"Treatment - Control Mean Diff\")\n    axs[i].set_ylabel(\"Frequency\")\n    axs[i].legend()\n\nplt.suptitle(\"Central Limit Theorem: Distribution of Mean Differences\")\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-17-output-1.png){width=1140 height=757}\n:::\n:::\n\n\nAs the sample size gets larger (50, 200, 500, 1,000), the distribution of average differences will be narrower, more symmetric, and closer to normal distribution.\n\nFor small samples (e.g., n = 50), the distribution is noisy and is closer to 0. As n becomes larger (e.g., n = 1,000), the distribution converges to normal and centers around the true effect (0.04).\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}